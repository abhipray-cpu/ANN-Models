# -*- coding: utf-8 -*-
"""flight delay multi class classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MRoXldGkUf7ChX7Yi156Zh7oMjzJC8bc
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import tensorflow as tf

tf.__version__

data=pd.read_csv('/content/full_data_flightdelay.csv')

data.sample(12)

data.columns

#this is the problem statement we need to predict the arrrival time of the flight based on the data

#preprocessing dataset
def get_type(data):
  numeric=[]
  categorical=[]
  for col in data.columns:
    if data[f'{col}'].dtypes == 'object':
      categorical.append(col)
    else:
      numeric.append(col)
  return {'numeric':numeric,'categorical':categorical}

# check for null values and deal with them
# this function will take the type of process as well for both numeric and categorical data
def treat_null_values(data,numeric_type:str='mean'):
  types=get_type(data)
  numeric=types['numeric']
  categorical=types['categorical']
  if numeric_type == 'mean':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].fillna(data[f'{col}'].mean())
  elif numeric_type == 'mode':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].fillna(data[f'{col}'].mode())
  elif numeric_type == 'median':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].fillna(data[f'{col}'].median())
  elif numeric_type == 'frequent':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].fillna(data[f'{col}'].nunique[0])
  elif numeric_type == 'drop':
    for col in numeric:
      data[f'{col}']=data[f'{col}'].dropnna(inplace=True)
  elif numeric_type == 'predictive_modeling':
    pass # create a seprate function for this
  elif numeric_type == 'impute':
    pass # create a seprate function for this as well
  
  for col in categorical:
    most_frequent_category=data[f'{col}'].mode()[0]
    data[f'{col}'].fillna(most_frequent_category,inplace=True)
  return data

  

def predictive_modeling():
  pass #do a detailed study as disadvantages for this model usually outweights advantages
def multiple_imputation():
  from fancyimpute import IterativeImputer as MICE
  data= pd.DataFrame(MICE().fit_transform(data))
  return data

def encode_data(data,multiclass:str='One_hot',binary_class:str='Label'): #this function takes three args one is the data 2nd is the type of encoding for multiclass data and third is the encoding for binary class data
  categorical=get_type(data)['categorical']
  multivariate=[]
  bivariate=[]
  for col in categorical:
    if data[f'{col}'].nunique()>2:
      multivariate.append(col)
    else:
      bivariate.append(col)
  
  if multiclass == 'One_hot':
    for col in multivariate:
      data=encode_and_bind(data,col)
  if binary_class == 'Label':
    for col in bivariate:
      data=label_encode(data,col)
  # add other sorting techniques as well in here
  return data

def encode_and_bind(original_dataframe, feature_to_encode):
    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])
    res = pd.concat([original_dataframe, dummies], axis=1)
    res.pop(feature_to_encode)
    return(res)

def label_encode(data,col):
  from sklearn.preprocessing import LabelEncoder
  encoder=LabelEncoder()
  data[col]=encoder.fit_transform(data[col])
  return data
  
# this function needs to be modified therefore add differenr sort of encoding techniques as well in this cll

# this function will perform all the data preprocessing steps
# incase you want to use non default algos call these function seprately
def preprocess_data(data,feature:str):
  data=treat_null_values(data)
  data=encode_data(data)
  last_column = data[feature]
  data.drop(feature, inplace=True, axis=1)
  data.insert(data.shape[1],feature,last_column)
  
  return data

# call outliers and balance function independentlu whenever you like and PS Fuck Roopa

data=preprocess_data(data,'AWND')

data.sample(12)

data.columns

data.shape

#splitng and scaling the data
x=data.iloc[:,:-1].values
y=data.iloc[:,-1].values
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=42)

#scaling the dataset
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train=sc.fit_transform(x_train)
x_test=sc.transform(x_test)

#building an ANN for predicting the arrival time of flights
ann=tf.keras.models.Sequential()

"""#Using this formulae for calculating number of neurons in hidden layer
Nh=Ns/(α∗(Ni+No))

Ni = number of input neurons.
No = number of output neurons.
Ns = number of samples in training data set.
α = an arbitrary scaling factor usually 2-10.

setting alpha=2
Ns=x_train.shape(0)
N0=1(since regression)
Ni=number of columns in dataset after preprocessing
"""

alpha=2
Ni=data.shape[1]
Ns=x_train.shape[0]
No=1#since regression

print(Ns/(alpha*(Ni+No)))
#calculate this value for different values of alpha and compare result

#threfore adding two layers with 25 hidden neurons
ann.add(tf.keras.layers.Dense(units=25,activation='relu'))#this is the first hidden layer
ann.add(tf.keras.layers.Dense(units=25,activation='relu'))#this is the second hidden layer
ann.add(tf.keras.layers.Dense(units=1))#this is the output layer and since regression therefore no activation function

!pip install tensor-dash

from tensordash.tensordash import Tensordash
histories=Tensordash(
    ModelName='ann regression (flight delay dataset)',
    email='dumkaabhipray@gmail.com',
    password='kamalanita1@'
)

#computing accuracy for our model
from keras import backend as K

def soft_acc(y_true, y_pred):
    return K.mean(K.equal(K.round(y_true), K.round(y_pred)))

#compiling the ann
ann.compile(optimizer='adam',loss='mean_squared_error',metrics=[soft_acc])

#training the neural network
try:
  ann.fit(x_train,y_train,batch_size=32,epochs=1000,callbacks=[histories])
except Exception as e:
  print(e)
  histories.sendCrash()

#1000 epochs is giving a model with 96% accuracy and the model is not overfitted

#checking model accuray on test set
#predicting test set results
y_pred=ann.predict(x_test)#this will simply return probablity
np.set_printoptions(precision=2)
res=np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)
print(res)

#visualizing the results
import seaborn as sns
ax1=sns.distplot(y_test,hist=False,color="r",label="actual value")
sns.distplot(y_pred,hist=False,color="b",label="predicted values",ax=ax1)