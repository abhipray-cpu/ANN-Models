{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ann Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Churn modeling:(This is a segmentation model that is used to segment users into two or more categories)"
      ],
      "metadata": {
        "id": "fRurzlrX4hli"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fWakMGy334Dk"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "PjD5L1iv422M",
        "outputId": "33f908ba-c6e4-4aa6-afa6-990789385fcf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data preprocessing**"
      ],
      "metadata": {
        "id": "hY6ZRJ3I5JeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=pd.read_csv('/content/Churn_Modelling.csv')\n",
        "x=dataset.iloc[:,3:-1].values\n",
        "y=dataset.iloc[:,-1].values\n"
      ],
      "metadata": {
        "id": "b4KWajsK5JBe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding categorical variables\n",
        "#label encoding gender\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "x[:,2]=le.fit_transform(x[:,2])\n"
      ],
      "metadata": {
        "id": "m6alQf4k5mOf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#one hot encoding country fields\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "ct=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[1])],remainder='passthrough')\n",
        "x=np.array(ct.fit_transform(x))"
      ],
      "metadata": {
        "id": "uNJ5CaFa5-f-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "G8P_KqGc6ixi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling the training set\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "st=StandardScaler()\n",
        "x_train=st.fit_transform(x_train)\n",
        "x_test=st.transform(x_test)"
      ],
      "metadata": {
        "id": "PJAvJKHL67jv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building the ANN**"
      ],
      "metadata": {
        "id": "FpW5W1SR7OYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#intializing the ANN\n",
        "ann=tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "atPT6KrK7N3G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding the input and first hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))"
      ],
      "metadata": {
        "id": "BbuWkrOO7aue"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding the second hidden layer\n",
        "ann.add(tf.keras.layers.Dense(units=6,activation='relu'))"
      ],
      "metadata": {
        "id": "-ERZ-ESx7nu7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding an output layer\n",
        "#for multivariate classification use softmax as acticvation function\n",
        "\n",
        "#use sigmoid as activation function for bivariarte/binary output\n",
        "ann.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "pcckyJfE7nxq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the ANN**"
      ],
      "metadata": {
        "id": "Al4LZcFW8AKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensor-dash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klLm_Nqg9fzD",
        "outputId": "dfb4d762-5a0e-463a-c65e-42765491024a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensor-dash\n",
            "  Downloading tensor_dash-1.8.1-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tensor-dash) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tensor-dash) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tensor-dash) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tensor-dash) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tensor-dash) (2.10)\n",
            "Installing collected packages: tensor-dash\n",
            "Successfully installed tensor-dash-1.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#compiling the ANN\n",
        "#this is for bivariate classification\n",
        "ann.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "#use this is for multivariate classification use categorical_crossentropy loss\n"
      ],
      "metadata": {
        "id": "-WJn53Cb7n0a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensordash.tensordash import Tensordash\n",
        "histories=Tensordash(\n",
        "    ModelName='ann Clasification (chur segmentation)',\n",
        "    email='dumkaabhipray@gmail.com',\n",
        "    password='kamalanita1@'\n",
        ")\n"
      ],
      "metadata": {
        "id": "plC3TCYw9lwK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the ANN\n",
        "try:\n",
        "  ann.fit(x_train,y_train,batch_size=32,epochs=100,callbacks=[histories])\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  histories.sendCrash()"
      ],
      "metadata": {
        "id": "bx_tMn_F9Bx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Making the predictions on the trained model**"
      ],
      "metadata": {
        "id": "nwMASoL89Jlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting test set results\n",
        "y_pred=ann.predict(x_test)#this will simply return probablity\n",
        "y_pred=(y_pred>0.5)#we need to convert probablity to some solid value based on some threshold value\n",
        "res=np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1)\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og5ytKZn_Vki",
        "outputId": "f9c29cb7-3dc3-45db-8849-dc65d08d791a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " ...\n",
            " [1 1]\n",
            " [0 1]\n",
            " [0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the results\n",
        "import seaborn as sns\n",
        "ax1=sns.distplot(y_test,hist=False,color=\"r\",label=\"actual value\")\n",
        "sns.distplot(y_pred,hist=False,color=\"b\",label=\"predicted values\",ax=ax1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "3NqpcYbbAQQn",
        "outputId": "076f297a-e6a1-4b23-ae3e-ca05eed8baa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f273867d7d0>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gMLYBVMAiCL",
        "outputId": "8b383ca9-76e0-4766-aa50-7ebc2071f0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1549   58]\n",
            " [ 210  183]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.866"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross validating the model using k-fold cross validation"
      ],
      "metadata": {
        "id": "Qh5aCXFuK-I2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#need to split data into different sets first\n",
        "#need to handle the crashed iteration\n",
        "dataSets=[]\n",
        "accuracies=[]\n",
        "for val in range(1,10):\n",
        "  print(f'this is the {val}th dataset split results')\n",
        "  x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25,random_state=val+7)\n",
        "  try:\n",
        "    history=ann.fit(np.asarray(x_train).astype(np.float32), np.asarray(y_train).astype(np.float32),batch_size=32,epochs=100,callbacks=[histories])\n",
        "    accuracies.append(history)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "  histories.sendCrash()"
      ],
      "metadata": {
        "id": "sm25qB75LFJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8067b499-db05-4ef9-dafd-af35a910017c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is the 1th dataset split results\n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 400.8252 - accuracy: 0.6727\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 42.9386 - accuracy: 0.6771\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 32.4326 - accuracy: 0.6897\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 21.5543 - accuracy: 0.6855\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 21.6447 - accuracy: 0.6833\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 18.3453 - accuracy: 0.6829\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 23.2062 - accuracy: 0.6936\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 18.9524 - accuracy: 0.6859\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 18.0107 - accuracy: 0.6837\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 14.7152 - accuracy: 0.6920\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 15.8343 - accuracy: 0.6868\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 17.1539 - accuracy: 0.6925\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 14.9061 - accuracy: 0.6880\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 14.7372 - accuracy: 0.6961\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 14.7936 - accuracy: 0.6867\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 16.7410 - accuracy: 0.6948\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 20.3154 - accuracy: 0.6873\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.1711 - accuracy: 0.6933\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 14.9485 - accuracy: 0.6875\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 17.4528 - accuracy: 0.6873\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 13.1642 - accuracy: 0.6967\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 16.9036 - accuracy: 0.6855\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 12.0763 - accuracy: 0.6824\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 11.4968 - accuracy: 0.6912\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.6587 - accuracy: 0.6933\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 14.3350 - accuracy: 0.6875\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 13.7318 - accuracy: 0.6951\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 13.2143 - accuracy: 0.6893\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.8312 - accuracy: 0.6945\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.4088 - accuracy: 0.6913\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 13.7775 - accuracy: 0.6923\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 12.7633 - accuracy: 0.6985\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.2592 - accuracy: 0.7017\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 12.1691 - accuracy: 0.6865\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 15.5402 - accuracy: 0.6853\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 11.9135 - accuracy: 0.6939\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 13.1926 - accuracy: 0.6901\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 13.2955 - accuracy: 0.6880\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 12.3579 - accuracy: 0.6871\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 14.0317 - accuracy: 0.6893\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.3199 - accuracy: 0.6901\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.7469 - accuracy: 0.6964\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.7945 - accuracy: 0.6980\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 11.5786 - accuracy: 0.6899\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.4737 - accuracy: 0.6888\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 16.6608 - accuracy: 0.6813\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 9.0021 - accuracy: 0.6987\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.6241 - accuracy: 0.6873\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 16.5799 - accuracy: 0.6827\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 15.6883 - accuracy: 0.6892\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 12.5219 - accuracy: 0.6976\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.8397 - accuracy: 0.6904\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 11.7851 - accuracy: 0.6975\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.7158 - accuracy: 0.7003\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 14.1046 - accuracy: 0.6993\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 11.2056 - accuracy: 0.6959\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.4333 - accuracy: 0.6979\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.6070 - accuracy: 0.6984\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.8857 - accuracy: 0.6969\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.8900 - accuracy: 0.6976\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0563 - accuracy: 0.6937\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.4257 - accuracy: 0.6995\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.6336 - accuracy: 0.7043\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 13.3817 - accuracy: 0.6932\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 13.9159 - accuracy: 0.6971\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.8729 - accuracy: 0.6985\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.2365 - accuracy: 0.7004\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 8.0889 - accuracy: 0.7097\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.8844 - accuracy: 0.7045\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.9120 - accuracy: 0.6979\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 11.2845 - accuracy: 0.6895\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.7570 - accuracy: 0.7019\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.0726 - accuracy: 0.7035\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.6297 - accuracy: 0.7003\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.8221 - accuracy: 0.7009\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.6109 - accuracy: 0.6979\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 10.8267 - accuracy: 0.6957\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.5488 - accuracy: 0.6928\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 2s 6ms/step - loss: 12.6237 - accuracy: 0.6936\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 2s 9ms/step - loss: 9.9771 - accuracy: 0.6939\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 10.8022 - accuracy: 0.6960\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.3652 - accuracy: 0.7028\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.3518 - accuracy: 0.7072\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.3941 - accuracy: 0.7039\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 12.8496 - accuracy: 0.6943\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.1253 - accuracy: 0.6945\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.7272 - accuracy: 0.7009\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0157 - accuracy: 0.7017\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.1657 - accuracy: 0.7015\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.9590 - accuracy: 0.7112\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.3715 - accuracy: 0.7043\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 10.2816 - accuracy: 0.7024\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.0069 - accuracy: 0.6997\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 12.0871 - accuracy: 0.6976\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.8141 - accuracy: 0.6939\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.8756 - accuracy: 0.7125\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.2075 - accuracy: 0.6992\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 12.1975 - accuracy: 0.6867\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.9213 - accuracy: 0.6947\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.4961 - accuracy: 0.6959\n",
            "this is the 2th dataset split results\n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.5952 - accuracy: 0.7065\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.3653 - accuracy: 0.6981\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.6887 - accuracy: 0.6980\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.6165 - accuracy: 0.6983\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.6659 - accuracy: 0.6903\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 10.9197 - accuracy: 0.6901\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.7337 - accuracy: 0.7104\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.4285 - accuracy: 0.7031\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.7051 - accuracy: 0.7140\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.9876 - accuracy: 0.7064\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.9812 - accuracy: 0.7071\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.4705 - accuracy: 0.6996\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.3216 - accuracy: 0.7072\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.1356 - accuracy: 0.7169\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.4675 - accuracy: 0.6987\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.1945 - accuracy: 0.7092\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.1741 - accuracy: 0.7023\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.2744 - accuracy: 0.7100\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.5747 - accuracy: 0.7085\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.5207 - accuracy: 0.7051\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.3715 - accuracy: 0.7060\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.5872 - accuracy: 0.7091\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.5272 - accuracy: 0.7103\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.9641 - accuracy: 0.7115\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.7998 - accuracy: 0.6972\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.0325 - accuracy: 0.6997\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.2344 - accuracy: 0.7032\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.4360 - accuracy: 0.7009\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.5364 - accuracy: 0.7059\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.2403 - accuracy: 0.7072\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 7.8648 - accuracy: 0.7084\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.7257 - accuracy: 0.7085\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.4877 - accuracy: 0.6948\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.4764 - accuracy: 0.7105\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.9666 - accuracy: 0.7092\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.5815 - accuracy: 0.7073\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.6224 - accuracy: 0.7051\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.4703 - accuracy: 0.7029\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.9691 - accuracy: 0.6985\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 7.8896 - accuracy: 0.7116\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 9.0134 - accuracy: 0.7104\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.3849 - accuracy: 0.7061\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.3729 - accuracy: 0.7092\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.9348 - accuracy: 0.7109\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.0025 - accuracy: 0.7116\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.9654 - accuracy: 0.7079\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.9151 - accuracy: 0.7032\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 9.7558 - accuracy: 0.7141\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.6331 - accuracy: 0.7188\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.7760 - accuracy: 0.7085\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.3836 - accuracy: 0.6992\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 5.9765 - accuracy: 0.7136\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.9036 - accuracy: 0.7093\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.6970 - accuracy: 0.7127\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.4395 - accuracy: 0.7159\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.5051 - accuracy: 0.7081\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.8727 - accuracy: 0.7119\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.7882 - accuracy: 0.6996\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.2692 - accuracy: 0.7192\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 8.4228 - accuracy: 0.7061\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.5259 - accuracy: 0.7139\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.5908 - accuracy: 0.7105\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.6992 - accuracy: 0.7149\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 5.6011 - accuracy: 0.7136\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 11.1756 - accuracy: 0.7035\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.9245 - accuracy: 0.7001\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.5483 - accuracy: 0.7124\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 5.8712 - accuracy: 0.7208\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.9091 - accuracy: 0.7045\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.7754 - accuracy: 0.7055\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 5.9286 - accuracy: 0.7211\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.3350 - accuracy: 0.7103\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.6391 - accuracy: 0.7081\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.9436 - accuracy: 0.7091\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.9080 - accuracy: 0.7080\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.0455 - accuracy: 0.7075\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.0160 - accuracy: 0.7101\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 5.5290 - accuracy: 0.7139\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.1598 - accuracy: 0.7176\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 8.6035 - accuracy: 0.7104\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.3447 - accuracy: 0.7103\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.5852 - accuracy: 0.7072\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.5635 - accuracy: 0.7125\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.7503 - accuracy: 0.7117\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.6743 - accuracy: 0.7131\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.2627 - accuracy: 0.7131\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 7.4801 - accuracy: 0.7079\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 6.2107 - accuracy: 0.7057\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.1750 - accuracy: 0.7059\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 5.6459 - accuracy: 0.7139\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.0191 - accuracy: 0.7125\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 5.3341 - accuracy: 0.7161\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 4.8019 - accuracy: 0.7193\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 7.1926 - accuracy: 0.7139\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.3504 - accuracy: 0.7133\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 7.2291 - accuracy: 0.7072\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 6.4760 - accuracy: 0.7061\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 7.6222 - accuracy: 0.7024\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 4.7640 - accuracy: 0.7203\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.8012 - accuracy: 0.7143\n",
            "this is the 3th dataset split results\n",
            "Epoch 1/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.4210 - accuracy: 0.7115\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.7352 - accuracy: 0.7144\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.3862 - accuracy: 0.7093\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.4656 - accuracy: 0.7037\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 5.8913 - accuracy: 0.7144\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.8580 - accuracy: 0.7100\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.1040 - accuracy: 0.7151\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 10.2978 - accuracy: 0.7084\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 7.4279 - accuracy: 0.7121\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 5.9296 - accuracy: 0.7167\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.3792 - accuracy: 0.7047\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 4.6300 - accuracy: 0.7249\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.8256 - accuracy: 0.7152\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.2426 - accuracy: 0.7156\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 8.9767 - accuracy: 0.7057\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.2868 - accuracy: 0.7092\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.6070 - accuracy: 0.7225\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 5.8172 - accuracy: 0.7187\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.2813 - accuracy: 0.7217\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 7.6028 - accuracy: 0.7069\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 6.4932 - accuracy: 0.7041\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 5.3433 - accuracy: 0.7120\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 6.8014 - accuracy: 0.7120\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 5.2703 - accuracy: 0.7187\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 4.8060 - accuracy: 0.7180\n",
            "Epoch 26/100\n",
            "188/235 [=======================>......] - ETA: 0s - loss: 5.2475 - accuracy: 0.7134"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def createDataFrames():\n",
        "  accuracy_Data=[]\n",
        "  loss_Data=[]\n",
        "  for history in accuracies:\n",
        "    accuracy_arr=[]\n",
        "    accuracy_arr.append(sum(history.history['accuracy']) / len(history.history['accuracy']))\n",
        "    loss_arr=[]\n",
        "    loss_arr.append(sum(history.history['loss']) / len(history.history['loss']))\n",
        "    for accuracy_val, loss_val in zip(history.history['accuracy'],history.history['loss']):\n",
        "      accuracy_arr.append(accuracy_val)\n",
        "      loss_arr.append(loss_val)\n",
        "    \n",
        "    accuracy_Data.append(accuracy_arr)\n",
        "    loss_Data.append(loss_arr)\n",
        "  #creating dataframes from these values\n",
        "  columns=['mean']\n",
        "  for i in range(1,101):\n",
        "    columns.append(f'Epoch{i}')\n",
        "  index=['CV1','CV2','CV3','CV4','CV5','CV6','CV7','CV8','CV9','CV10']\n",
        "\n",
        "  #this is the dataframe for accuracies\n",
        "  accuracy_DF = pd.DataFrame(data=accuracy_Data,index=index,columns=columns)\n",
        "  accuracy_DF = accuracy_DF.sort_values(by=['mean'],ascending=False)\n",
        "  #this is the dataframe for losses\n",
        "  loss_DF = pd.DataFrame(data=loss_Data,index=index,columns=columns)\n",
        "  loss_DF = loss_DF.sort_values(by=['mean'],ascending=False)\n",
        "\n",
        "  return {'accuracies':accuracy_DF,'losses':loss_DF}\n",
        "\n",
        "dfs=createDataFrames()"
      ],
      "metadata": {
        "id": "J08Q80O8skDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the accuracy dataframe\n",
        "print(dfs['accuracies'])"
      ],
      "metadata": {
        "id": "826iYKavyON3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this is the loss dataframe\n",
        "print(dfs['losses'])"
      ],
      "metadata": {
        "id": "dAq10PE4yUBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'This is the mean accuracy of the model after applying 10 cross validations {dfs[\"accuracies\"][\"mean\"].mean()}')"
      ],
      "metadata": {
        "id": "stbynNlJyjSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'This is the mean loss of the model after applying 10 cross validations {dfs[\"losses\"][\"mean\"].mean()}')"
      ],
      "metadata": {
        "id": "BSA7K9YkzM23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#processing the dataset to get a mapping for the categorical values\n",
        "#this will keep a track of all the encodings that we will be using to preprocess the data that will be fed to the trained model for predictions\n",
        "preProcess_dataset=pd.read_csv('/content/Churn_Modelling.csv').iloc[:,4:6].values\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "Gender_unique = np.unique(preProcess_dataset[:,1])\n",
        "Country_unique = np.unique(preProcess_dataset[:,0])\n"
      ],
      "metadata": {
        "id": "nqF0bo_yzeer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_1dZ-YR94Aqs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genderDict={}\n",
        "for val1,val2 in zip(Gender_unique,le.fit_transform(Gender_unique)):\n",
        "  genderDict[val1]=val2"
      ],
      "metadata": {
        "id": "7obJSUxY5qrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countryDict={}\n",
        "ct1=ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder='passthrough')\n",
        "for val1,val2 in zip(preProcess_dataset[:,0],np.array(ct1.fit_transform(preProcess_dataset))):\n",
        "  countryDict[val1]=val2[:-1]\n",
        "\n",
        "print(countryDict)"
      ],
      "metadata": {
        "id": "3n2JR7bn6-WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#writing a function that taken in an input and then gives an output based on the trained model\n",
        "#in these functions need to apply inverse transformation to the input values to fit model requirements\n",
        "\n",
        "#pass in the values and use the trained model to predict the results\n",
        "#using names parameters here\n",
        "def predictResults(\n",
        "    RowNumber:int,CustomeId:int,Surname:str,\n",
        "    CreditScore:int,Geography:str,Gender:'str',\n",
        "    Age:int,Tenure:int,Balance:float,NumOfProducts:int,\n",
        "    HasCard:int,IsActiveMember:int,EstimatedSalary:float,):\n",
        "  featureArr=np.array([CreditScore,countryDict[Geography][0],countryDict[Geography][1],countryDict[Geography][2],genderDict[Gender],\n",
        "    Age,Tenure,Balance,NumOfProducts,HasCard,IsActiveMember,EstimatedSalary])\n",
        "  features=st.transform([[CreditScore,countryDict[Geography][0],countryDict[Geography][1],countryDict[Geography][2],genderDict[Gender],\n",
        "    Age,Tenure,Balance,NumOfProducts,HasCard,IsActiveMember,EstimatedSalary]])\n",
        "  if ann.predict(features)>0.5:\n",
        "    return 'will'\n",
        "  else:\n",
        "    return 'will not'\n",
        "\n",
        "\n",
        "result=predictResults(1,15634602\t,'Hargrave'\t,619,\t'France',\t'Female'\t,42,\t2,\t0,\t1,\t1,\t1,\t101348.88)\n",
        "print(f'the user {result} leave the firm')"
      ],
      "metadata": {
        "id": "zqF_2GIyA4ej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}